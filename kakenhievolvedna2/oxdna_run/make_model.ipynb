{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a24b2a-7f65-4f19-b15f-85b5c6e98a14",
   "metadata": {
    "tags": []
   },
   "source": [
    "z参考：\n",
    "https://aws.amazon.com/jp/what-is/boosting/#:~:text=%E3%83%96%E3%83%BC%E3%82%B9%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0%E3%81%AF%E3%80%81%E4%BA%88%E6%B8%AC%E3%83%87%E3%83%BC%E3%82%BF,%E3%83%87%E3%83%BC%E3%82%BF%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%E6%8E%A8%E6%B8%AC%E3%81%97%E3%81%BE%E3%81%99%E3%80%82\n",
    "\n",
    "https://stackoverflow.com/questions/67149980/ensemble-forecast-with-keras-on-gpu\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html#sklearn.ensemble.BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2a81289d-00a2-4e4f-84b1-e142403dca82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import GPy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import importlib\n",
    "import config as cfg\n",
    "importlib.reload(cfg)\n",
    "import make_filepath as mpath\n",
    "importlib.reload(mpath)\n",
    "import use_pickle\n",
    "importlib.reload(use_pickle)\n",
    "import seaborn as sns\n",
    "# Make NumPy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "#まずpil_maker.pyを実行してpilファイルを生成してください\n",
    "#pilファイルができたら、get_output_pilfile.pyでoxDNAを実行してください\n",
    "#get_strand_data.pyでstrand一覧CSVを生成してください\n",
    "#最後にこのプログラムを使ってください\n",
    "import time\n",
    "import csv\n",
    "from scipy.stats import linregress\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2d8a3309-a7fc-4123-803b-a83ff1adc7be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn import model_selection, svm, datasets\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a6ab09-a20a-40f9-9754-d5152bcc9b02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_df_for_learning(dirpath):\n",
    "    df = pd.read_csv(os.path.join(dirpath,\"strands.csv\"))\n",
    "    df_groupby = df.groupby(\"pilfile_path\")\n",
    "    #df[\"pilfile_path\"].values\n",
    "    df_groupby.get_group(df[\"pilfile_path\"].values[0])#.loc[:,\"strand_num\"])\n",
    "    #strand_set_numは理論上、0 ~ 255まで存在する。\n",
    "    path_strands_binary = []\n",
    "    for i, data in enumerate(df_groupby):\n",
    "        test_df = data[1]\n",
    "        arr = [\"0\"] * 256\n",
    "        strand_list = []\n",
    "        for i,num in enumerate(test_df.loc[:,\"strand_set_num\"].values):\n",
    "            arr[255-num] = \"1\"\n",
    "            #strand_list.append[test_df.loc[:,\"strand_set\"]]\n",
    "        #print(test_df.loc[:,\"strand_set\"])\n",
    "        energy_path = os.path.dirname(data[0]) + \"/energy_log.csv\"\n",
    "        oxdna_energy_mean = pd.read_csv(energy_path).loc[:,\"potential_energy\"].mean\n",
    "\n",
    "\n",
    "        try:\n",
    "            oxdna_energy_mean = pd.read_csv(energy_path).loc[:,\"potential_energy\"].mean()\n",
    "\n",
    "            #path_strands_binary.append([data[0],int(\"\".join(arr),2),energy])\n",
    "            path_strands_binary.append(\n",
    "                [data[0],\n",
    "                 list(test_df.loc[:,\"strand_set\"]),\n",
    "                 arr,\n",
    "                 int(\"\".join(arr),2),oxdna_energy_mean]\n",
    "            )\n",
    "        except:\n",
    "            #path_strands_binary.append([data[0],int(\"\".join(arr),2),None])\n",
    "            path_strands_binary.append(\n",
    "                [data[0],\n",
    "                 list(test_df.loc[:,\"strand_set\"]),\n",
    "                 arr,\n",
    "                 int(\"\".join(arr),2),\n",
    "                 None]\n",
    "            )\n",
    "    binary_strands_energy_data = pd.DataFrame(path_strands_binary)\n",
    "    binary_strands_energy_data.columns = [\"path\",\"strands\",\"code_num\",\"code_num2\",\"oxdna_energy_mean\"]\n",
    "    binary_strands_energy_data.to_csv(os.path.join(cfg.result_parent_dir,\"binary_strands_energy_data.csv\"),index=False)\n",
    "    df01 = pd.DataFrame([])\n",
    "    for lst in binary_strands_energy_data.loc[:,\"code_num\"].values:\n",
    "        #display(pd.DataFrame(lst).T)\n",
    "        df01 = pd.concat([df01,pd.DataFrame(lst).T]).reset_index(drop=True).astype(int)\n",
    "        df_binary_strands_energy = pd.concat([df01,pd.DataFrame(binary_strands_energy_data.loc[:,\"oxdna_energy_mean\"])],axis=1)\n",
    "        df_binary_strands_energy = pd.concat([df_binary_strands_energy,binary_strands_energy_data.loc[:,\"strands\"]],axis=1)\n",
    "        df_binary_strands_energy = df_binary_strands_energy.dropna()\n",
    "        \n",
    "    use_pickle.dump_to_pickle(dirpath,[df_binary_strands_energy],[\"df_binary_strands_energy\"])\n",
    "    return df_binary_strands_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "92325c80-dcb3-4c29-8fba-ce9f141094dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirpath = \"2022-12-19/20230723_1529/loop0\"\n",
    "# make_df_for_learning(dirpath).iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f807090b-e059-4052-952a-dc8ba84e4d55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_datasets(dirpath,df_binary_strands_energy):\n",
    "    \n",
    "    dataset0 = df_binary_strands_energy.copy()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        dataset0.drop([\"oxdna_energy_mean\",\"strands\"],axis = 1),\n",
    "        dataset0.loc[:,\"oxdna_energy_mean\"],\n",
    "        test_size=0.2\n",
    "    )\n",
    "    \n",
    "    #strandsを含むデータセットをファイルに保存しておく。\n",
    "    \n",
    "    ytrain_mean = y_train.mean()\n",
    "    ytrain_std = y_train.std()\n",
    "\n",
    "    ytest_mean = y_test.mean()\n",
    "    ytest_std = y_test.std()\n",
    "    \n",
    "    # variable_list = [x_train,y_train,x_test,y_test,x_train0,y_train0,x_test0,y_test0]\n",
    "    variable_list = [x_train,y_train,x_test,y_test]\n",
    "\n",
    "    #namelist = [\"x_train\",\"y_train\",\"x_test\",\"y_test\",\"x_train0\",\"y_train0\",\"x_test0\",\"y_test0\"]\n",
    "    namelist = [\"x_train\",\"y_train\",\"x_test\",\"y_test\"]\n",
    "    use_pickle.dump_to_pickle(dirpath,variable_list,namelist)\n",
    "\n",
    "    return x_train,y_train,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1c23d575-a889-4eab-881a-a7291070bdc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    print(hist.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "65ab4e37-d4c9-4376-8416-4c42a851a134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_svm(dirpath,param_filename,gamma,C,epsilon,\n",
    "             kernel=\"rbf\",degree=3,coef0=0.0,tol=0.001,\n",
    "             shrinking=True,cache_size=200,\n",
    "             verbose=False,max_iter= -1):\n",
    "    \n",
    "    with open(os.path.join(dirpath,param_filename), \"w\") as f:\n",
    "        f.write(\"kernel:\"+\"\\t\"+str(kernel)+\"\\n\")\n",
    "        f.write(\"degree:\"+\"\\t\"+str(degree)+\"\\n\")\n",
    "        f.write(\"gamma:\"+\"\\t\"+str(gamma)+\"\\n\")\n",
    "        f.write(\"coef0:\"+\"\\t\"+str(coef0)+\"\\n\")\n",
    "        f.write(\"tol:\"+\"\\t\"+str(tol)+\"\\n\")\n",
    "        f.write(\"C:\"+\"\\t\"+str(C)+\"\\n\")\n",
    "        f.write(\"epsilon:\"+\"\\t\"+str(epsilon)+\"\\n\")\n",
    "        f.write(\"shrinking:\"+\"\\t\"+str(shrinking)+\"\\n\")\n",
    "        f.write(\"cache_size:\"+\"\\t\"+str(cache_size)+\"\\n\")\n",
    "        f.write(\"verbose:\"+\"\\t\"+str(verbose)+\"\\n\")\n",
    "        f.write(\"max_iter:\"+\"\\t\"+str(max_iter)+\"\\n\")\n",
    "    f.close()\n",
    "    svr = SVR(gamma=gamma,C=C,epsilon=epsilon,\n",
    "             kernel=kernel,degree=degree,coef0=coef0,tol=tol,\n",
    "             shrinking=shrinking,cache_size=cache_size,\n",
    "             verbose=verbose,max_iter= max_iter)\n",
    "    return svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffb7ea09-325a-4fc4-924f-8fc7339dd2b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_svm_result(dirpath,train_filename,test_filename,model,x_train,y_train,x_test,y_test):\n",
    "    #ndarrayに変換\n",
    "    xtn = x_train.values\n",
    "    ytn = y_train.values\n",
    "    xtt = x_test.values\n",
    "    ytt = y_test.values\n",
    "    #学習結果\n",
    "    svm_train_result = pd.concat(\n",
    "    [pd.DataFrame(model.predict(xtn)),\n",
    "     y_train.reset_index(drop=True),\n",
    "     pd.DataFrame(model.predict(xtn)-ytn)],\n",
    "    axis = 1)\n",
    "    svm_train_result.index = y_train.index\n",
    "    svm_train_result.columns = [\"predicted_train\",\"y_train\",\"defference\"]\n",
    "    \n",
    "    #テスト結果\n",
    "    svm_test_result = pd.concat(\n",
    "    [pd.DataFrame(model.predict(xtt)),\n",
    "     y_test.reset_index(drop=True),\n",
    "     pd.DataFrame(model.predict(xtt)-ytt)],\n",
    "    axis = 1)\n",
    "    svm_test_result.index = y_test.index\n",
    "    svm_test_result.columns = [\"predicted_test\",\"y_test\",\"defference\"]\n",
    "\n",
    "\n",
    "    return svm_train_result,svm_test_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9228f96a-6b8f-4153-a5a8-0d10c3a3993c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_optimized_svm(dirpath,Xtrain,ytrain,Xtest,ytest,bagging=False):\n",
    "    #試したいパラメータの候補。\n",
    "    svrcs = 2**np.arange( -5, 11, dtype=float)          # Candidates of C\n",
    "    svrepsilons = 2**np.arange( -10, 1, dtype=float)    # Candidates of epsilon\n",
    "    svrgammas = 2**np.arange( -20, 11, dtype=float)     # Candidates of gamma\n",
    "    foldnumber = 5 # \"foldnumber\"-fold cross-validation\n",
    "    nmberoftrainingsamples = len(Xtrain)\n",
    "    nmberoftestsamples = len(Xtest)\n",
    "    \n",
    "    # autoscaledXtrain = (Xtrain - Xtrain.mean(axis=0)) / Xtrain.std(axis=0, ddof=1)\n",
    "    # autoscaledytrain = (ytrain - ytrain.mean()) / ytrain.std(ddof=1)\n",
    "    # autoscaledXtest =  (Xtest - Xtrain.mean(axis=0)) / Xtrain.std(axis=0, ddof=1)\n",
    "    #標準化するとNaNがたくさんできるので、今回は使っていない\n",
    "    \n",
    "    autoscaledXtrain = Xtrain\n",
    "    autoscaledytrain = ytrain\n",
    "    autoscaledXtest = Xtest\n",
    "    \n",
    "    #Optimize gamma by maximizing variance in Gram matrix\n",
    "    numpyautoscaledXtrain = np.array(autoscaledXtrain)\n",
    "    varianceofgrammatrix = list()\n",
    "    for svrgamma in svrgammas:\n",
    "        #grammatrix = np.exp(-svrgamma*((numpyautoscaledXtrain[:, np.newaxis] - numpyautoscaledXtrain)**2).sum(axis=2))\n",
    "        a =  -svrgamma*((numpyautoscaledXtrain[:, np.newaxis] - numpyautoscaledXtrain)**2)\n",
    "        grammatrix = np.exp(np.nansum(a,axis=2))\n",
    "        varianceofgrammatrix.append(grammatrix.var(ddof=1))\n",
    "        \n",
    "    optimalsvrgamma = svrgammas[ np.where( varianceofgrammatrix == np.max(varianceofgrammatrix) )[0][0] ]\n",
    "        \n",
    "    # Optimize epsilon with cross-validation\n",
    "    svrmodelincv = GridSearchCV(svm.SVR(kernel='rbf', C=3, gamma=optimalsvrgamma), {'epsilon':svrepsilons}, cv=foldnumber )\n",
    "    svrmodelincv.fit(autoscaledXtrain, autoscaledytrain)\n",
    "    optimalsvrepsilon = svrmodelincv.best_params_['epsilon']\n",
    "    \n",
    "    # Optimize C with cross-validation\n",
    "    svrmodelincv = GridSearchCV(svm.SVR(kernel='rbf', epsilon=optimalsvrepsilon, gamma=optimalsvrgamma), {'C':svrcs}, cv=foldnumber )\n",
    "    svrmodelincv.fit(autoscaledXtrain, autoscaledytrain)\n",
    "    optimalsvrc = svrmodelincv.best_params_['C']\n",
    "\n",
    "    # Optimize gamma with cross-validation (optional)\n",
    "    svrmodelincv = GridSearchCV(svm.SVR(kernel='rbf', epsilon=optimalsvrepsilon, C=optimalsvrc), {'gamma':svrgammas}, cv=foldnumber )\n",
    "    svrmodelincv.fit(autoscaledXtrain, autoscaledytrain)\n",
    "    optimalsvrgamma = svrmodelincv.best_params_['gamma']\n",
    "    \n",
    "    print (\"C: {0}, Epsion: {1}, Gamma: {2}\".format(optimalsvrc, optimalsvrepsilon, optimalsvrgamma))\n",
    "    \n",
    "    #regressionmodel = svm.SVR(kernel='rbf', C=optimalsvrc, epsilon=optimalsvrepsilon, gamma=optimalsvrgamma)\n",
    "    regressionmodel = make_svm(dirpath,\"param_optimized_svm.txt\",optimalsvrgamma,optimalsvrc,optimalsvrepsilon)\n",
    "    use_pickle.dump_to_pickle(dirpath,[regressionmodel],[\"empty_svm\"])\n",
    "    regressionmodel.fit(autoscaledXtrain, autoscaledytrain)\n",
    "    use_pickle.dump_to_pickle(dirpath,[regressionmodel],[\"model\"])\n",
    "    \n",
    "    #ついでなので、baggingを適用したものも追加。\n",
    "    if bagging:\n",
    "        regr2 = BaggingRegressor(estimator=regressionmodel,\n",
    "                             n_estimators=10,\n",
    "                             random_state=0)\n",
    "        regr2.fit(autoscaledXtrain, autoscaledytrain)\n",
    "        use_pickle.dump_to_pickle(dirpath,[regr2],[\"bagging_model\"])\n",
    "        return regressionmodel,regr2\n",
    "    \n",
    "    return regressionmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0f00abc-66d4-4672-a158-ff0e516e5572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(datasets_dirpath,results_dirpath):\n",
    "    df_binary_strands_energy = make_df_for_learning(datasets_dirpath)\n",
    "    x_train,y_train,x_test,y_test = make_datasets(results_dirpath,df_binary_strands_energy)\n",
    "    #regressionmodel,bagging_regressionmodel = make_optimized_svm(dirpath,x_train,y_train,x_test,y_test)\n",
    "    regressionmodel = make_optimized_svm(results_dirpath,x_train,y_train,x_test,y_test)\n",
    "    svm_train_result,svm_test_result = make_svm_result(\n",
    "        results_dirpath,\n",
    "        \"train_result\",\n",
    "        \"test_result\",\n",
    "        regressionmodel,\n",
    "        x_train,y_train,x_test,y_test)\n",
    "    use_pickle.dump_to_pickle(results_dirpath,[svm_train_result,svm_test_result],[\"svm_train_result\",\"svm_test_result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37c532f2-8239-40b0-b722-c774f8778948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_for_loop(datasets_dirpath,results_dirpath):\n",
    "    x_train = use_pickle.read_pickle(results_dirpath,\"x_train.p\")\n",
    "    y_train = use_pickle.read_pickle(results_dirpath,\"y_train.p\")\n",
    "    x_test = use_pickle.read_pickle(datasets_dirpath,\"x_test.p\")\n",
    "    y_test = use_pickle.read_pickle(datasets_dirpath,\"y_test.p\")\n",
    "    use_pickle.dump_to_pickle(results_dirpath,[x_test,y_test],[\"x_test\",\"y_test\"])\n",
    "    regressionmodel = make_optimized_svm(results_dirpath,x_train,y_train,x_test,y_test)\n",
    "    svm_train_result,svm_test_result = make_svm_result(\n",
    "        results_dirpath,\n",
    "        \"train_result\",\n",
    "        \"test_result\",\n",
    "        regressionmodel,\n",
    "        x_train,y_train,x_test,y_test)\n",
    "    use_pickle.dump_to_pickle(results_dirpath,[svm_train_result,svm_test_result],[\"svm_train_result\",\"svm_test_result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6337d9f8-7cc8-463c-b7d7-cf408a45321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use_pickle.read_pickle(\"2022-12-19/test\",\"x_train.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d31c9b2-6a25-4c56-b0ed-bc60fb76275a",
   "metadata": {},
   "source": [
    "## 参考にした文献\n",
    "https://datachemeng.com/fastoptsvrhyperparams/\n",
    "\n",
    "https://github.com/hkaneko1985/fastoptsvrhyperparams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "import subprocess as sp\n",
    "from multiprocessing.pool import Pool\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import functools\n",
    "\n",
    "import find_trap as findtrap\n",
    "import run_output_bonds_func as robf\n",
    "# import convexhull as cvh\n",
    "# import vista_func as vf\n",
    "import get_coordinate as gc\n",
    "import config as cfg\n",
    "import read_energy_file as reef\n",
    "importlib.reload(findtrap)\n",
    "importlib.reload(robf)\n",
    "#importlib.reload(cvh)\n",
    "#importlib.reload(vf)\n",
    "importlib.reload(cfg)\n",
    "importlib.reload(reef)\n",
    "\n",
    "oxDNA_dir = cfg.oxDNA_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ab_length(data):\n",
    "    for line in data:\n",
    "        if \"length\" in line:\n",
    "            length_a_str = line         \n",
    "            length_b_str = data[data.index(line)+1]\n",
    "            break\n",
    "    length_a = int(re.sub(r\"\\D\", \"\", length_a_str))#13\n",
    "    length_b = int(re.sub(r\"\\D\", \"\", length_b_str))#13\n",
    "    return {\"a\" : length_a, \"b\" : length_b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_e0(data):\n",
    "    startpoint = \"\"\n",
    "    for line in data:\n",
    "        if \"Resting complexes\" in line:\n",
    "            startpoint = data.index(line)+1\n",
    "    return startpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_end(data, start_index):\n",
    "    for line in data[start_index:]:\n",
    "        if \"s\" in line:\n",
    "            return data.index(line)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_random_DNA(length):\n",
    "    for x in range(length):\n",
    "        result1 = random.choices([\"A\",\"T\",\"G\",\"C\"],k=length)\n",
    "        result2 = ''.join(result1)\n",
    "    return result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_comp_DNA(str):\n",
    "    result = ''\n",
    "    for x in str:\n",
    "        if x == \"A\":\n",
    "            result = result+\"T\"\n",
    "        if x == \"T\":\n",
    "            result = result+\"A\"\n",
    "        if x ==\"G\":\n",
    "            result = result+\"C\"\n",
    "        if x == \"C\":\n",
    "            result = result+\"G\"\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_filename(line, output_dir):\n",
    "    where_space = line.find(' ')\n",
    "    filename_e = line[0:where_space]\n",
    "    filename  =  output_dir + '/{}.txt'.format(filename_e)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_front_two(line, index):\n",
    "    #*ã®ï¼‘ã¤å‰ã‚’è¿”ã™ã€‚\n",
    "    if line[index]== '*':\n",
    "        return line[index-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def complementary(domain):\n",
    "    if domain[-1] == \"*\":#*ã‚’æ¤œçŸ¥ã—ãŸå ´åˆã€\n",
    "        return domain[:-1]#è¦‹ãŸåˆ—ã«ã¤ã„ã¦ã€Œå…ˆé ­ã€œå¾Œã‚ã‹ã‚‰æ•°ãˆã¦ï¼’ç•ªç›®ã€ã®åˆ—ã‚’è¿”ã™\n",
    "    return domain+\"*\"#ãã†ã§ãªã‘ã‚Œã°ã€*ã‚’ã¤ã‘ã¦è¦‹ãŸåˆ—ã‚’ãã®ã¾ã¾è¿”ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replace_parentheses(given_string):\n",
    "    print(\"replace_parentheses() : start\\n\")\n",
    "    print(\"string : \", given_string, \"\\n\")\n",
    "    given_string = given_string.split(\"=\")[1]\n",
    "    stack = []#ä»Šè¦‹ã¦ã„ã‚‹æ‹¬å¼§ã¨ãƒãƒƒãƒã•ã›ã‚‹æ‹¬å¼§ã‚’ç½®ãã‚¹ã‚¿ãƒƒã‚¯ã€‚\n",
    "    strand_list = []#strandãŒã§ããŸã‚‰ã€ã“ã“ã«è²¯ã‚ã‚‹ã€‚\n",
    "    current_strand = []#ç¾åœ¨è¦‹ã¦ã„ã‚‹strandã‚’ä½œã‚‹ã€‚a,b,*ã‹ã‚‰ãªã‚‹ã€‚\n",
    "    accumulate = []#current_strandã«è¿½åŠ ã™ã‚‹æ–‡å­—ã‚’æ ¼ç´ã™ã‚‹ã€‚\n",
    "    \n",
    "    num = 0#ãã‚Œãã‚Œã®ãƒšã‚¢ã®id\n",
    "    numpile = []\n",
    "    \n",
    "    for index, character in enumerate(given_string):#indexã¯ä½¿ã‚ãªã„ã€‚\n",
    "        #print(\"index, character : \", index, \" , \", character)\n",
    "        if character == ' ' or character =='\\n':\n",
    "            if accumulate: #is not [ ]\n",
    "                current_strand.append((''.join(accumulate), -1))#accumulateãŒç©ºã§ãªã‘ã‚Œã°ã€ãã‚Œã‚’æ–‡å­—åˆ—åŒ–ã—ã¦current_strandã«è¿½åŠ \n",
    "                accumulate = []#è¿½åŠ ã—ãŸå¾Œã¯ç©ºã«ã™ã‚‹ã€‚    \n",
    "                #ã‚‚ã¨ã‚‚ã¨ç©ºã®å ´åˆã¯ä½•ã‚‚ã—ãªã„ã€‚                \n",
    "            \n",
    "        elif character == '(':#é–‹ãæ‹¬å¼§ã®å ´åˆ\n",
    "            if accumulate:\n",
    "                current_strand.append((''.join(accumulate), num))\n",
    "                #joinéƒ¨åˆ†ã¯ã€accumulateã‚’æ–‡å­—åˆ—åŒ–ã—ãŸã‚‚ã®ã‚’è¿”ã™\n",
    "                accumulate = []#è¿½åŠ ã—ãŸå¾Œã¯ç©ºã«ã™ã‚‹ã€‚    \n",
    "                numpile.append(num)\n",
    "                num += 1 #numã¯\"(\"ãŒç¾ã‚Œã‚‹ãŸã³ã«ã‚«ã‚¦ãƒ³ãƒˆã•ã‚Œã‚‹ã€‚ãƒšã‚¢ã”ã¨ã«ç•ªå·ãŒå‰²ã‚ŠæŒ¯ã‚‰ã‚Œã‚‹ã€‚\n",
    "            stack.append(current_strand[-1][0])#ç¾åœ¨ã®æ–‡å­—åˆ—ã®æœ€å¾Œå°¾ã‚’stackã«è¿½åŠ \n",
    "        \n",
    "        elif character == \")\":#é–‰ã˜æ‹¬å¼§ã®å ´åˆ\n",
    "            current_strand.append((complementary(stack.pop()), numpile.pop()))\n",
    "            #st.popã§stã«æœ€å¾Œã«å…¥ã‚ŒãŸã‚‚ã®ã‚’å–ã‚Šå‡ºã—ã€complementaryã«ä¸ãˆã‚‹ã€‚\n",
    "            #complementaryã«stackã‹ã‚‰å–ã‚Šå‡ºã—ãŸã‚‚ã®ã‚’ä¸ãˆã‚‹ã¨ã€æœ€å¾Œã«è¦‹ãŸ\" ( \"ã«å¯¾å¿œã™ã‚‹ã€\" ) \"ã®ç½®ãæ›ãˆå…ˆãŒè¿”ã‚‹ã€‚\n",
    "            \n",
    "        elif character == \"+\":\n",
    "            strand_list.append(current_strand)#strandã®åŒºåˆ‡ã‚Šã€‚strandã‚’strand_listã«ä¸ãˆã¦ã€current_strandã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹ã€‚\n",
    "            current_strand = []\n",
    "            \n",
    "        else:#strandã®æ–‡å­—åˆ—ã§ã‚ã‚Œã°\n",
    "            accumulate.append(character)#accumulateã«è¿½åŠ ã™ã‚‹ã€‚\n",
    "            \n",
    "        #print(\"accumulate : \", accumulate)\n",
    "        #print (\"current_strand : \", current_strand, \"\\n\")\n",
    "\n",
    "\n",
    "    if current_strand: # is not [ ] \n",
    "        strand_list.append(current_strand)#æœ€å¾Œã«current_strandã«æ®‹ã£ãŸã‚‚ã®ã‚’strand_listã«è¿½åŠ \n",
    "    return strand_list#ãƒªã‚¹ãƒˆã®å„è¦ç´ ã¯ã€['a', 'b*']ã®ã‚ˆã†ãªå½¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_file(line, str_a, str_b, str_a_star, str_b_star, output_ATGC_folder):\n",
    "    filename = create_filename(line, output_ATGC_folder)\n",
    "    replaced_linelist = replace_parentheses(line)#ã“ã“ã§ãƒªã‚¹ãƒˆã«å¤‰åŒ–ã™ã‚‹\n",
    "    #[[('a*', 0), ('b', 1)], [('a*', -1), ('b*', 1)], [('a', 0), ('b', 2)], [('a*', -1), ('b*', 2)]]\n",
    "    #print(replaced_linelist, \"\\n\")\n",
    "    dic = {'a': str_a, 'b':str_b , 'a*': str_a_star, 'b*': str_b_star}\n",
    "\n",
    "    file = open(filename, 'w')#ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹\n",
    "    for item in replaced_linelist:\n",
    "        text = \"\"\n",
    "        for char, num in item:\n",
    "            if char in dic.keys():#replaced_linelistã«ã¯eã€‡ã€‡ = ãŒæ®‹ã£ã¦ã„ã‚‹ã®ã§ã€è¾æ›¸ã«å½“ã¦ã¯ã¾ã‚‰ãªã„ã‚‚ã®ã¯ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã€‚\n",
    "                text += ''.join(dic[char])\n",
    "        file.writelines(text)\n",
    "        file.writelines('\\n')\n",
    "    file.close()\n",
    "    return filename, replaced_linelist\n",
    "    #ATGCã®å¡©åŸºé…åˆ—ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã§ãã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate-sa.py å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_generate_sa(target, output_oxdna_dir, output_ATGC_dir, \n",
    "                    box_size = 30,  \n",
    "                    oxdna_path = oxDNA_dir):\n",
    "    executable = [\"python2\", \n",
    "                  os.path.join(oxdna_path, \"UTILS\", \"generate-sa-takeguchi.py\"), \n",
    "                  str(box_size),\n",
    "                  os.path.join(output_ATGC_dir,\"{}.txt\".format(target)), \n",
    "                  os.path.join(output_oxdna_dir, target)]\n",
    "    #stdout\n",
    "    print(\"command: \",executable)\n",
    "    with open(os.path.join(output_oxdna_dir,target+\"_generate_sa_log.txt\"),\"w\") as logfile:\n",
    "        sp.run(executable, stdout=logfile, stderr = logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def read_input(input_file = \"input_relax_1e5\"):\n",
    "def read_input(input_file = cfg.oxdna_input):\n",
    "    input_filename = input_file\n",
    "    with open(input_filename ,'r') as file:\n",
    "        input_data = file.readlines()\n",
    "    return input_data#list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## oxdnaå…¥åŠ›ã‚’ä½œã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_oxdna_inputs(input_data, target, output_dir , kakenhievolvedna_path = \"../../kakenhievolvedna2/oxdna_run\",trap_file_make = True):\n",
    "    #inputs_filename = os.path.join(output_dir, target + \"_input_relax_1e5\")\n",
    "    inputs_filename = os.path.join(output_dir, target + \"_\" + cfg.oxdna_input)\n",
    "    file = open(inputs_filename, 'w')#ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹\n",
    "    for text in input_data:\n",
    "        if \"topology =\" in text:\n",
    "           # file.writelines(\"topology = \"+ kakenhievolvedna_path + output_dir + \"/{}.top\\n\".format(target))\n",
    "            file.writelines(\"topology = \" + os.path.join(kakenhievolvedna_path, output_dir, \"{}.top\\n\".format(target)))\n",
    "        elif \"conf_file =\" in text:\n",
    "            file.writelines(\"conf_file = \" + os.path.join(kakenhievolvedna_path, output_dir, \"{}.dat\\n\".format(target)))\n",
    "        elif \"energy_file\" in text:\n",
    "            file.writelines(\"energy_file = \" + os.path.join(kakenhievolvedna_path, output_dir, \"{}_energy.dat\\n\".format(target)))\n",
    "        elif \"trajectory_file\" in text:\n",
    "            file.writelines(\"trajectory_file = \" + os.path.join(kakenhievolvedna_path, output_dir, \"{}_trajectory.dat\\n\".format(target)))\n",
    "        elif \"lastconf_file\" in text:\n",
    "            file.writelines(\"lastconf_file = \" + os.path.join(kakenhievolvedna_path, output_dir, \"{}_lastconf.dat\\n\".format(target)))\n",
    "        else:\n",
    "            file.writelines(text)\n",
    "    if trap_file_make == True:\n",
    "        file.writelines([\"## External force\\n\",\n",
    "                         \"external_forces = 1\\n\",\n",
    "                         \"external_forces_file= \" + os.path.join(kakenhievolvedna_path, output_dir, \"{}_external.conf\\n\".format(target))])\n",
    "    file.close()\n",
    "    return inputs_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## oxdnaã‚’å®Ÿè¡Œã™ã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_oxdna(target, target_input, oxdna_exe = \"oxDNA\", oxdna_path = os.path.join(oxDNA_dir, \"build/bin\")):\n",
    "    exefile = os.path.join(oxdna_path, oxdna_exe)\n",
    "    print(\"exefile : \", exefile)\n",
    "    executable = [exefile, target_input]#./oxDNA <inputfile>\n",
    "    print(\"exe : \", executable)\n",
    "    print(\"command: \",executable)\n",
    "    with open(os.path.join(os.path.dirname(target_input),target+\"_run_oxdna_log.txt\"),\"w\") as logfile:\n",
    "        sp.run(executable, stdout=logfile, stderr = logfile)\n",
    "    #ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å†…ã®å‡ºåŠ›è¨­å®šã‚’ç›´æ¥æ›¸ãæ›ãˆã‚‹ã¨renameã¯ä¸è¦\n",
    "    \n",
    "    #oxdnaå®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã¨confãƒ•ã‚¡ã‚¤ãƒ«ã€datãƒ•ã‚¡ã‚¤ãƒ«ãŒåŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å­˜åœ¨ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pdbã‚’ä½œã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$oxDNA/UTILS/traj2chimera.py <trajectory> <topology> \n",
    "\n",
    "def make_pdb(target, output_oxdna_dir, oxdna_path = os.path.join(oxDNA_dir, \"UTILS\")):\n",
    "    trajectory_file = os.path.join(output_oxdna_dir, target + \"_lastconf.dat\")\n",
    "    topology_file = os.path.join(output_oxdna_dir, target + \".top\")\n",
    "    traj2chimera_file = os.path.join(oxdna_path, \"traj2chimera.py\")\n",
    "    executable = [\"python2\", traj2chimera_file, trajectory_file, topology_file]\n",
    "\n",
    "    with open(os.path.join(output_oxdna_dir, target + \"_chimera_log.txt\"),\"w\") as logfile:\n",
    "        sp.run(executable, stdout = logfile, stderr = logfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é€šã—ã§å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(num, data, input_data, \n",
    "             str_a, str_b, str_a_star, str_b_star, \n",
    "             length_dict, output_folder, output_ATGC_folder,\n",
    "             energy_log_path):\n",
    "    #print(\"simuration start\\n\")\n",
    "    line = data[num]\n",
    "    print(\"simulating line : \", line, \"\\n\")\n",
    "    filename, replaced_linelist = write_file(line, str_a, str_b, str_a_star, str_b_star, output_ATGC_folder)\n",
    "    target = os.path.splitext(os.path.basename(filename))[0]#eã€‡ã€‡ã¨ã„ã†æ–‡å­—åˆ—\n",
    "    print(\"target : \", target)\n",
    "    sys.stdout.flush() \n",
    "    print(\"making trap file... \")#success\n",
    "    sys.stdout.flush() \n",
    "    domain_list = findtrap.make_trap(replaced_linelist, length_dict, target, output_folder)\n",
    "    print(\"created domain list: \", domain_list)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    #generate_sa.pyã‚’å®Ÿè¡Œã™ã‚‹\n",
    "    print(\"running generate_sa.py: \", target)\n",
    "    sys.stdout.flush() \n",
    "    run_generate_sa(target, output_folder, output_ATGC_folder)#generate_saã®å®Ÿè¡Œçµæœï¼ˆè¤‡æ•°ï¼‰ãŒoutput_oxDNAã«è“„ç©\n",
    "    print(\"created: top and conf :\" , target)\n",
    "    sys.stdout.flush()\n",
    "    print(\"creating oxDNA input file.... : \", target)\n",
    "    sys.stdout.flush() \n",
    "    #oxDNAå®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹\n",
    "    target_input = make_oxdna_inputs(input_data, target, output_folder)#oxDNAå…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒeã€‡ã€‡ã”ã¨ã«ä½œæˆã•ã‚Œã‚‹\n",
    "    print(\"created: \", target_input)\n",
    "    sys.stdout.flush() \n",
    "\n",
    "    to_evaluate = True\n",
    "    while to_evaluate:\n",
    "        to_evaluate = False\n",
    "        print(\"running oxdna... : \", target)\n",
    "        sys.stdout.flush() \n",
    "        run_oxdna(target, target_input)\n",
    "\n",
    "        #run_oxdnaã®å¾Œã€last_conf?dat?ã‚’è¦‹ã¦ã€ã‚‚ã—e+**ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°ã‚„ã‚Šç›´ã—ãŸã»ã†ãŒã‚ˆã•ãã†ã§ã‚ã‚‹\n",
    "        lastconfpath = os.path.join(output_folder, target + \"_lastconf.dat\")\n",
    "        with open (lastconfpath, \"r\") as lastconffile:\n",
    "            print(\"searching the overflow... :\", target)\n",
    "            sys.stdout.flush() \n",
    "            for line in lastconffile:\n",
    "                if re.search(\"e\\+\", line) :\n",
    "                    print(\"overflow found: \", target)\n",
    "                    sys.stdout.flush() \n",
    "                    print(line)#debag\n",
    "                    to_evaluate = True\n",
    "                    break#for ã‹ã‚‰æŠœã‘ã‚‹\n",
    "\n",
    "        print(\"{} run_oxdna() end\\n\".format(target))\n",
    "    #run_generate_saã®æ™‚ç‚¹ã§ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ç™ºç”ŸãŒæ±ºã¾ã£ã¦ã—ã¾ã£ã¦ã„ãŸå ´åˆã€\n",
    "    #run_oxdnaã‚’ç¹°ã‚Šè¿”ã—ã¦ç„¡é™ãƒ«ãƒ¼ãƒ—ã«ãªã‚‹æã‚ŒãŒã‚ã‚‹\n",
    "    #ãã“ã§ã€run_generate_saã‹ã‚‰ã®ã‚„ã‚Šç›´ã—ã‹ã€\n",
    "    #æ•°å›ã‚„ã£ã¦å…¨éƒ¨ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ãªã‚‰å¼·åˆ¶çµ‚äº†ã‹ã€ç„¡è¦–ã—ã¦æ¬¡ã¸é€²ã‚€ã‹ã«ãªã‚‹ã ã‚ã†\n",
    "    print(\"oxDNA completed : \", target, \"\\ncreating pdb file....\")\n",
    "    sys.stdout.flush() \n",
    "    make_pdb(target, output_folder)\n",
    "    print(\"{} pdb file :completed\".format(target), \"\\ncreating connection dataframe...\")\n",
    "    sys.stdout.flush() \n",
    "    connection_data, expected_num_strands, actual_num_strands = robf.create_connection_data(target, output_folder)\n",
    "    print(\"{} connection_data: created dataframe\".format(target), \"\\ncalcurating convex_hull and cube volume...\")\n",
    "    sys.stdout.flush() \n",
    "    \n",
    "    \n",
    "    #è¨ˆæ¸¬ã—ãŸã‚µã‚¤ã‚ºã‚’å–å¾—ã™ã‚‹\n",
    "#     convexhull_volume = cvh.convexhull_volume(connection_data, target, output_folder)\n",
    "#     print(\"volume of convex hull: \", convexhull_volume)\n",
    "#     sys.stdout.flush() \n",
    "    \n",
    "#     cube_volume = gc.get_cube_volume(connection_data)\n",
    "#     print(\"volume of cube: \", cube_volume)\n",
    "#     sys.stdout.flush() \n",
    "    \n",
    "    #æ–°ã—ãã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚‚å–å¾—ã™ã‚‹\n",
    "    #energy_file = os.path.join(output_folder,\"/{}_energy.dat\".format(target))\n",
    "    energy = reef.potential_energy_mean(output_folder,target)\n",
    "    print(\"potential energy: \",energy)\n",
    "    sys.stdout.flush() \n",
    "    \n",
    "    #display(connection_data)\n",
    "\n",
    "    #logfilename = output_folder + \"/{}_sizelog.txt\".format(target)\n",
    "\n",
    "    with open(energy_log_path, \"a\") as energy_log:\n",
    "        energy_log.writelines([target.replace(\"e\", \"\"),\",\",\n",
    "                    str(expected_num_strands), \",\", \n",
    "                    str(actual_num_strands), \",\", \n",
    "                    str(energy), \"\\n\"])\n",
    "        energy_log.close()\n",
    "\n",
    "    #logfile.writelines([\"id\",\",\",\"cube\",\",\", \"convex hull\", \",\", \"expected_number_of_strands\", \",\", \"actual_number_of_strands\", \",\", \"potential_energy\", \"\\n\"])\n",
    "    \n",
    "    #logfile.writelines([target.replace(\"e\", \"\"),\",\",str(cube_volume),\",\",str(convexhull_volume), \",\", str(expected_num_strands), \",\", str(actual_num_strands), \",\", str(energy), \"\\n\"])\n",
    "   \n",
    "    \n",
    "    \n",
    "    print(\"{} : all simuration process were completed\\n\".format(target))\n",
    "    sys.stdout.flush() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å…¥åŠ›ã‚’å–å¾—ã—ã¦simurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_output(data, output_folder,output_ATGC_folder,energy_log_path):\n",
    "    \n",
    "    length_dict= get_ab_length(data) ## TODO: Not compatible with L3\n",
    "    length_a = length_dict[\"a\"]\n",
    "    length_b = length_dict[\"b\"]\n",
    "    head_index = get_e0(data) \n",
    "    print(\"head index : \",head_index, \" data : \", data[head_index], \"\\n\")\n",
    "    end_index = get_end(data,head_index)\n",
    "    print(\"end index : \", end_index, \" data : \", data[end_index], \"\\n\")\n",
    "    str_a = get_random_DNA(length_a)\n",
    "    str_b = get_random_DNA(length_b)\n",
    "    str_a_star = get_comp_DNA(str_a)\n",
    "    str_b_star = get_comp_DNA(str_b)\n",
    "    sys.stdout.flush()\n",
    "        \n",
    "    print(\"output folder : \", output_folder, \"\\n\")\n",
    "    \n",
    "    input_data = read_input()#oxDNAã®input\n",
    "\n",
    "    # cube_data = pd.DataFrame(index=[], columns=[\"size\"])    \n",
    "    # convexhull_data = pd.DataFrame(index=[], columns=[\"size\"])\n",
    "    for num in range(head_index, end_index):\n",
    "        simulate(num, \n",
    "                 data, input_data, \n",
    "                 str_a, str_b, str_a_star, str_b_star, \n",
    "                 length_dict, output_folder, output_ATGC_folder,\n",
    "                 energy_log_path)\n",
    "        print(\"data[{}]: simulated\".format(num))\n",
    "        sys.stdout.flush()\n",
    "    #for num in range(head_index, end_index):\n",
    "    # evalu = functools.partial(simulate, \n",
    "    #                           data = data, \n",
    "    #                           input_data = input_data, \n",
    "    #                           str_a = str_a, \n",
    "    #                           str_b = str_b,\n",
    "    #                           str_a_star = str_a_star,  \n",
    "    #                           str_b_star = str_b_star,\n",
    "    #                           length_dict = length_dict, \n",
    "    #                           output_folder = output_folder, \n",
    "    #                           output_ATGC_folder = output_ATGC_folder)\n",
    "    # print(\"eval set OK\\n\")\n",
    "    # with Pool(cfg.poolnum) as p:\n",
    "    #     res = p.map(evalu, range(head_index, end_index+1))\n",
    "    # sys.stdout.flush()\n",
    "    # print(\"map end ğŸ—º\\n\")\n",
    "    \n",
    "    \n",
    "#     record_cube = pd.Series([a for a,_ in res])\n",
    "#     record_convexhull = pd.Series([a for _,a in res])\n",
    "\n",
    "#     cube_data = pd.DataFrame({\"size\":record_cube})\n",
    "#     convexhull_data = pd.DataFrame({\"size\":record_convexhull})\n",
    "\n",
    "#     cube_data.plot()\n",
    "#     plt.savefig('test_cube.png')\n",
    "#     convexhull_data.plot()\n",
    "#     plt.savefig('test_convexhull.png')\n",
    "    return data[head_index], data[end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oxdna_energy_mean(energy_log_path):\n",
    "    energy_log = pd.read_csv(energy_log_path)\n",
    "    energy_mean = energy_log.loc[:,\"potential_energy\"].mean()\n",
    "    \n",
    "    with open(os.path.dirname(energy_log_path)+\"/oxdna_energy_mean.csv\",\"w\") as f:\n",
    "        f.writelines([\"oxdna_energy_mean\",\"\\n\",str(energy_mean)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    \n",
    "    #sys.argv[1]ã¯output***.pil, sys.argv[2]ã¯å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹\n",
    "    with open(args[1],'r') as file:#sys.argv[1]ã¯output***.pil\n",
    "\n",
    "        data = file.readlines()\n",
    "        #get_output_pilfile.pyã‹ã‚‰ã€argsã¨ã—ã¦å‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ã‚’å—ã‘å–ã‚‹\n",
    "        output_ATGC_folder = args[2]#sys.argv[2]ã¯å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹\n",
    "        output_folder = args[2]\n",
    "        \n",
    "        energy_log_path = output_folder + \"/energy_log.csv\"\n",
    "        if not os.path.exists(output_ATGC_folder):\n",
    "            os.makedirs(output_ATGC_folder)\n",
    "\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "            \n",
    "        with open(energy_log_path,\"w\") as energy_log:\n",
    "            energy_log.writelines([\"id\",\",\",\n",
    "                                   \"expected_number_of_strands\", \",\",\n",
    "                                   \"actual_number_of_strands\", \",\", \n",
    "                                   \"potential_energy\", \"\\n\"])\n",
    "        start, end = make_output(\n",
    "            data, output_folder, output_ATGC_folder,energy_log_path)\n",
    "        #ä»Šå¾Œmake_outputã«æ¸¡ã™å‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€åã¯ä¸€ã¤ã«çµ±åˆã—ãŸã„ã€‚\n",
    "        oxdna_energy_mean(energy_log_path)\n",
    "        \n",
    "        print (\"simuration complete : \\n\")\n",
    "        print(\"start : \", start)\n",
    "        print(\"end : \", end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "# import glob\n",
    "# import os\n",
    "# for pils in glob.glob(\"2023-07-31/sim_result_peppercorn*/*_result.pil\"):\n",
    "#     main([\"\",pils,os.path.dirname(pils)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    args = sys.argv\n",
    "    sys.exit(main(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9.0",
   "language": "python",
   "name": "python3.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc-autonumbering": false,
  "vscode": {
   "interpreter": {
    "hash": "cf26dc9fe348c759e74c27c0008c9a61c31eebfc82e2eaec1db085887aa19aca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

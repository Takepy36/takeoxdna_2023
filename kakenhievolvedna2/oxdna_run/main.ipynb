{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "import subprocess as sp\n",
    "from multiprocessing.pool import Pool\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import functools\n",
    "\n",
    "import find_trap as findtrap\n",
    "import run_output_bonds_func as robf\n",
    "# import convexhull as cvh\n",
    "# import vista_func as vf\n",
    "import get_coordinate as gc\n",
    "import config as cfg\n",
    "import read_energy_file as reef\n",
    "importlib.reload(findtrap)\n",
    "importlib.reload(robf)\n",
    "#importlib.reload(cvh)\n",
    "#importlib.reload(vf)\n",
    "importlib.reload(cfg)\n",
    "importlib.reload(reef)\n",
    "\n",
    "oxDNA_dir = cfg.oxDNA_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ab_length(data):\n",
    "    for line in data:\n",
    "        if \"length\" in line:\n",
    "            length_a_str = line         \n",
    "            length_b_str = data[data.index(line)+1]\n",
    "            break\n",
    "    length_a = int(re.sub(r\"\\D\", \"\", length_a_str))#13\n",
    "    length_b = int(re.sub(r\"\\D\", \"\", length_b_str))#13\n",
    "    return {\"a\" : length_a, \"b\" : length_b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_e0(data):\n",
    "    startpoint = \"\"\n",
    "    for line in data:\n",
    "        if \"Resting complexes\" in line:\n",
    "            startpoint = data.index(line)+1\n",
    "    return startpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_end(data, start_index):\n",
    "    for line in data[start_index:]:\n",
    "        if \"s\" in line:\n",
    "            return data.index(line)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_random_DNA(length):\n",
    "    for x in range(length):\n",
    "        result1 = random.choices([\"A\",\"T\",\"G\",\"C\"],k=length)\n",
    "        result2 = ''.join(result1)\n",
    "    return result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_comp_DNA(str):\n",
    "    result = ''\n",
    "    for x in str:\n",
    "        if x == \"A\":\n",
    "            result = result+\"T\"\n",
    "        if x == \"T\":\n",
    "            result = result+\"A\"\n",
    "        if x ==\"G\":\n",
    "            result = result+\"C\"\n",
    "        if x == \"C\":\n",
    "            result = result+\"G\"\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_filename(line, output_dir):\n",
    "    where_space = line.find(' ')\n",
    "    filename_e = line[0:where_space]\n",
    "    filename  =  output_dir + '/{}.txt'.format(filename_e)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_front_two(line, index):\n",
    "    #*の１つ前を返す。\n",
    "    if line[index]== '*':\n",
    "        return line[index-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def complementary(domain):\n",
    "    if domain[-1] == \"*\":#*を検知した場合、\n",
    "        return domain[:-1]#見た列について「先頭〜後ろから数えて２番目」の列を返す\n",
    "    return domain+\"*\"#そうでなければ、*をつけて見た列をそのまま返す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replace_parentheses(given_string):\n",
    "    print(\"replace_parentheses() : start\\n\")\n",
    "    print(\"string : \", given_string, \"\\n\")\n",
    "    given_string = given_string.split(\"=\")[1]\n",
    "    stack = []#今見ている括弧とマッチさせる括弧を置くスタック。\n",
    "    strand_list = []#strandができたら、ここに貯める。\n",
    "    current_strand = []#現在見ているstrandを作る。a,b,*からなる。\n",
    "    accumulate = []#current_strandに追加する文字を格納する。\n",
    "    \n",
    "    num = 0#それぞれのペアのid\n",
    "    numpile = []\n",
    "    \n",
    "    for index, character in enumerate(given_string):#indexは使わない。\n",
    "        #print(\"index, character : \", index, \" , \", character)\n",
    "        if character == ' ' or character =='\\n':\n",
    "            if accumulate: #is not [ ]\n",
    "                current_strand.append((''.join(accumulate), -1))#accumulateが空でなければ、それを文字列化してcurrent_strandに追加\n",
    "                accumulate = []#追加した後は空にする。    \n",
    "                #もともと空の場合は何もしない。                \n",
    "            \n",
    "        elif character == '(':#開き括弧の場合\n",
    "            if accumulate:\n",
    "                current_strand.append((''.join(accumulate), num))\n",
    "                #join部分は、accumulateを文字列化したものを返す\n",
    "                accumulate = []#追加した後は空にする。    \n",
    "                numpile.append(num)\n",
    "                num += 1 #numは\"(\"が現れるたびにカウントされる。ペアごとに番号が割り振られる。\n",
    "            stack.append(current_strand[-1][0])#現在の文字列の最後尾をstackに追加\n",
    "        \n",
    "        elif character == \")\":#閉じ括弧の場合\n",
    "            current_strand.append((complementary(stack.pop()), numpile.pop()))\n",
    "            #st.popでstに最後に入れたものを取り出し、complementaryに与える。\n",
    "            #complementaryにstackから取り出したものを与えると、最後に見た\" ( \"に対応する、\" ) \"の置き換え先が返る。\n",
    "            \n",
    "        elif character == \"+\":\n",
    "            strand_list.append(current_strand)#strandの区切り。strandをstrand_listに与えて、current_strandをリセットする。\n",
    "            current_strand = []\n",
    "            \n",
    "        else:#strandの文字列であれば\n",
    "            accumulate.append(character)#accumulateに追加する。\n",
    "            \n",
    "        #print(\"accumulate : \", accumulate)\n",
    "        #print (\"current_strand : \", current_strand, \"\\n\")\n",
    "\n",
    "\n",
    "    if current_strand: # is not [ ] \n",
    "        strand_list.append(current_strand)#最後にcurrent_strandに残ったものをstrand_listに追加\n",
    "    return strand_list#リストの各要素は、['a', 'b*']のような形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_file(line, str_a, str_b, str_a_star, str_b_star, output_ATGC_folder):\n",
    "    filename = create_filename(line, output_ATGC_folder)\n",
    "    replaced_linelist = replace_parentheses(line)#ここでリストに変化する\n",
    "    #[[('a*', 0), ('b', 1)], [('a*', -1), ('b*', 1)], [('a', 0), ('b', 2)], [('a*', -1), ('b*', 2)]]\n",
    "    #print(replaced_linelist, \"\\n\")\n",
    "    dic = {'a': str_a, 'b':str_b , 'a*': str_a_star, 'b*': str_b_star}\n",
    "\n",
    "    file = open(filename, 'w')#ファイルを作成する\n",
    "    for item in replaced_linelist:\n",
    "        text = \"\"\n",
    "        for char, num in item:\n",
    "            if char in dic.keys():#replaced_linelistにはe〇〇 = が残っているので、辞書に当てはまらないものはスキップする。\n",
    "                text += ''.join(dic[char])\n",
    "        file.writelines(text)\n",
    "        file.writelines('\\n')\n",
    "    file.close()\n",
    "    return filename, replaced_linelist\n",
    "    #ATGCの塩基配列のファイルができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate-sa.py 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_generate_sa(target, output_oxdna_dir, output_ATGC_dir, \n",
    "                    box_size = 30,  \n",
    "                    oxdna_path = oxDNA_dir):\n",
    "    executable = [\"python2\", \n",
    "                  os.path.join(oxdna_path, \"UTILS\", \"generate-sa-takeguchi.py\"), \n",
    "                  str(box_size),\n",
    "                  os.path.join(output_ATGC_dir,\"{}.txt\".format(target)), \n",
    "                  os.path.join(output_oxdna_dir, target)]\n",
    "    #stdout\n",
    "    print(\"command: \",executable)\n",
    "    with open(os.path.join(output_oxdna_dir,target+\"_generate_sa_log.txt\"),\"w\") as logfile:\n",
    "        sp.run(executable, stdout=logfile, stderr = logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def read_input(input_file = \"input_relax_1e5\"):\n",
    "def read_input(input_file = cfg.oxdna_input):\n",
    "    input_filename = input_file\n",
    "    with open(input_filename ,'r') as file:\n",
    "        input_data = file.readlines()\n",
    "    return input_data#list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## oxdna入力を作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_oxdna_inputs(input_data, target, output_dir , kakenhievolvedna_path = \"../../kakenhievolvedna2/oxdna_run\",trap_file_make = True):\n",
    "    #inputs_filename = os.path.join(output_dir, target + \"_input_relax_1e5\")\n",
    "    inputs_filename = os.path.join(output_dir, target + \"_\" + cfg.oxdna_input)\n",
    "    file = open(inputs_filename, 'w')#ファイルを作成する\n",
    "    for text in input_data:\n",
    "        if \"topology =\" in text:\n",
    "           # file.writelines(\"topology = \"+ kakenhievolvedna_path + output_dir + \"/{}.top\\n\".format(target))\n",
    "            file.writelines(\"topology = \" + os.path.join(kakenhievolvedna_path, output_dir, \"{}.top\\n\".format(target)))\n",
    "        elif \"conf_file =\" in text:\n",
    "            file.writelines(\"conf_file = \" + os.path.join(kakenhievolvedna_path, output_dir, \"{}.dat\\n\".format(target)))\n",
    "        elif \"energy_file\" in text:\n",
    "            file.writelines(\"energy_file = \" + os.path.join(kakenhievolvedna_path, output_dir, \"{}_energy.dat\\n\".format(target)))\n",
    "        elif \"trajectory_file\" in text:\n",
    "            file.writelines(\"trajectory_file = \" + os.path.join(kakenhievolvedna_path, output_dir, \"{}_trajectory.dat\\n\".format(target)))\n",
    "        elif \"lastconf_file\" in text:\n",
    "            file.writelines(\"lastconf_file = \" + os.path.join(kakenhievolvedna_path, output_dir, \"{}_lastconf.dat\\n\".format(target)))\n",
    "        else:\n",
    "            file.writelines(text)\n",
    "    if trap_file_make == True:\n",
    "        file.writelines([\"## External force\\n\",\n",
    "                         \"external_forces = 1\\n\",\n",
    "                         \"external_forces_file= \" + os.path.join(kakenhievolvedna_path, output_dir, \"{}_external.conf\\n\".format(target))])\n",
    "    file.close()\n",
    "    return inputs_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## oxdnaを実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_oxdna(target, target_input, oxdna_exe = \"oxDNA\", oxdna_path = os.path.join(oxDNA_dir, \"build/bin\")):\n",
    "    exefile = os.path.join(oxdna_path, oxdna_exe)\n",
    "    print(\"exefile : \", exefile)\n",
    "    executable = [exefile, target_input]#./oxDNA <inputfile>\n",
    "    print(\"exe : \", executable)\n",
    "    print(\"command: \",executable)\n",
    "    with open(os.path.join(os.path.dirname(target_input),target+\"_run_oxdna_log.txt\"),\"w\") as logfile:\n",
    "        sp.run(executable, stdout=logfile, stderr = logfile)\n",
    "    #テキストファイル内の出力設定を直接書き換えるとrenameは不要\n",
    "    \n",
    "    #oxdna実行ファイルとconfファイル、datファイルが同じディレクトリに存在する必要がある。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pdbを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$oxDNA/UTILS/traj2chimera.py <trajectory> <topology> \n",
    "\n",
    "def make_pdb(target, output_oxdna_dir, oxdna_path = os.path.join(oxDNA_dir, \"UTILS\")):\n",
    "    trajectory_file = os.path.join(output_oxdna_dir, target + \"_lastconf.dat\")\n",
    "    topology_file = os.path.join(output_oxdna_dir, target + \".top\")\n",
    "    traj2chimera_file = os.path.join(oxdna_path, \"traj2chimera.py\")\n",
    "    executable = [\"python2\", traj2chimera_file, trajectory_file, topology_file]\n",
    "\n",
    "    with open(os.path.join(output_oxdna_dir, target + \"_chimera_log.txt\"),\"w\") as logfile:\n",
    "        sp.run(executable, stdout = logfile, stderr = logfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## シミュレーションを通しで実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(num, data, input_data, \n",
    "             str_a, str_b, str_a_star, str_b_star, \n",
    "             length_dict, output_folder, output_ATGC_folder,\n",
    "             energy_log_path):\n",
    "    #print(\"simuration start\\n\")\n",
    "    line = data[num]\n",
    "    print(\"simulating line : \", line, \"\\n\")\n",
    "    filename, replaced_linelist = write_file(line, str_a, str_b, str_a_star, str_b_star, output_ATGC_folder)\n",
    "    target = os.path.splitext(os.path.basename(filename))[0]#e〇〇という文字列\n",
    "    print(\"target : \", target)\n",
    "    sys.stdout.flush() \n",
    "    print(\"making trap file... \")#success\n",
    "    sys.stdout.flush() \n",
    "    domain_list = findtrap.make_trap(replaced_linelist, length_dict, target, output_folder)\n",
    "    print(\"created domain list: \", domain_list)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    #generate_sa.pyを実行する\n",
    "    print(\"running generate_sa.py: \", target)\n",
    "    sys.stdout.flush() \n",
    "    run_generate_sa(target, output_folder, output_ATGC_folder)#generate_saの実行結果（複数）がoutput_oxDNAに蓄積\n",
    "    print(\"created: top and conf :\" , target)\n",
    "    sys.stdout.flush()\n",
    "    print(\"creating oxDNA input file.... : \", target)\n",
    "    sys.stdout.flush() \n",
    "    #oxDNA実行ファイルを実行する\n",
    "    target_input = make_oxdna_inputs(input_data, target, output_folder)#oxDNA入力ファイルがe〇〇ごとに作成される\n",
    "    print(\"created: \", target_input)\n",
    "    sys.stdout.flush() \n",
    "\n",
    "    to_evaluate = True\n",
    "    while to_evaluate:\n",
    "        to_evaluate = False\n",
    "        print(\"running oxdna... : \", target)\n",
    "        sys.stdout.flush() \n",
    "        run_oxdna(target, target_input)\n",
    "\n",
    "        #run_oxdnaの後、last_conf?dat?を見て、もしe+**が含まれていればやり直したほうがよさそうである\n",
    "        lastconfpath = os.path.join(output_folder, target + \"_lastconf.dat\")\n",
    "        with open (lastconfpath, \"r\") as lastconffile:\n",
    "            print(\"searching the overflow... :\", target)\n",
    "            sys.stdout.flush() \n",
    "            for line in lastconffile:\n",
    "                if re.search(\"e\\+\", line) :\n",
    "                    print(\"overflow found: \", target)\n",
    "                    sys.stdout.flush() \n",
    "                    print(line)#debag\n",
    "                    to_evaluate = True\n",
    "                    break#for から抜ける\n",
    "\n",
    "        print(\"{} run_oxdna() end\\n\".format(target))\n",
    "    #run_generate_saの時点でオーバーフロー発生が決まってしまっていた場合、\n",
    "    #run_oxdnaを繰り返して無限ループになる恐れがある\n",
    "    #そこで、run_generate_saからのやり直しか、\n",
    "    #数回やって全部オーバーフローなら強制終了か、無視して次へ進むかになるだろう\n",
    "    print(\"oxDNA completed : \", target, \"\\ncreating pdb file....\")\n",
    "    sys.stdout.flush() \n",
    "    make_pdb(target, output_folder)\n",
    "    print(\"{} pdb file :completed\".format(target), \"\\ncreating connection dataframe...\")\n",
    "    sys.stdout.flush() \n",
    "    connection_data, expected_num_strands, actual_num_strands = robf.create_connection_data(target, output_folder)\n",
    "    print(\"{} connection_data: created dataframe\".format(target), \"\\ncalcurating convex_hull and cube volume...\")\n",
    "    sys.stdout.flush() \n",
    "    \n",
    "    \n",
    "    #計測したサイズを取得する\n",
    "#     convexhull_volume = cvh.convexhull_volume(connection_data, target, output_folder)\n",
    "#     print(\"volume of convex hull: \", convexhull_volume)\n",
    "#     sys.stdout.flush() \n",
    "    \n",
    "#     cube_volume = gc.get_cube_volume(connection_data)\n",
    "#     print(\"volume of cube: \", cube_volume)\n",
    "#     sys.stdout.flush() \n",
    "    \n",
    "    #新しくエネルギーも取得する\n",
    "    #energy_file = os.path.join(output_folder,\"/{}_energy.dat\".format(target))\n",
    "    energy = reef.potential_energy_mean(output_folder,target)\n",
    "    print(\"potential energy: \",energy)\n",
    "    sys.stdout.flush() \n",
    "    \n",
    "    #display(connection_data)\n",
    "\n",
    "    #logfilename = output_folder + \"/{}_sizelog.txt\".format(target)\n",
    "\n",
    "    with open(energy_log_path, \"a\") as energy_log:\n",
    "        energy_log.writelines([target.replace(\"e\", \"\"),\",\",\n",
    "                    str(expected_num_strands), \",\", \n",
    "                    str(actual_num_strands), \",\", \n",
    "                    str(energy), \"\\n\"])\n",
    "        energy_log.close()\n",
    "\n",
    "    #logfile.writelines([\"id\",\",\",\"cube\",\",\", \"convex hull\", \",\", \"expected_number_of_strands\", \",\", \"actual_number_of_strands\", \",\", \"potential_energy\", \"\\n\"])\n",
    "    \n",
    "    #logfile.writelines([target.replace(\"e\", \"\"),\",\",str(cube_volume),\",\",str(convexhull_volume), \",\", str(expected_num_strands), \",\", str(actual_num_strands), \",\", str(energy), \"\\n\"])\n",
    "   \n",
    "    \n",
    "    \n",
    "    print(\"{} : all simuration process were completed\\n\".format(target))\n",
    "    sys.stdout.flush() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力を取得してsimurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_output(data, output_folder,output_ATGC_folder,energy_log_path):\n",
    "    \n",
    "    length_dict= get_ab_length(data) ## TODO: Not compatible with L3\n",
    "    length_a = length_dict[\"a\"]\n",
    "    length_b = length_dict[\"b\"]\n",
    "    head_index = get_e0(data) \n",
    "    print(\"head index : \",head_index, \" data : \", data[head_index], \"\\n\")\n",
    "    end_index = get_end(data,head_index)\n",
    "    print(\"end index : \", end_index, \" data : \", data[end_index], \"\\n\")\n",
    "    str_a = get_random_DNA(length_a)\n",
    "    str_b = get_random_DNA(length_b)\n",
    "    str_a_star = get_comp_DNA(str_a)\n",
    "    str_b_star = get_comp_DNA(str_b)\n",
    "    sys.stdout.flush()\n",
    "        \n",
    "    print(\"output folder : \", output_folder, \"\\n\")\n",
    "    \n",
    "    input_data = read_input()#oxDNAのinput\n",
    "\n",
    "    # cube_data = pd.DataFrame(index=[], columns=[\"size\"])    \n",
    "    # convexhull_data = pd.DataFrame(index=[], columns=[\"size\"])\n",
    "    for num in range(head_index, end_index):\n",
    "        simulate(num, \n",
    "                 data, input_data, \n",
    "                 str_a, str_b, str_a_star, str_b_star, \n",
    "                 length_dict, output_folder, output_ATGC_folder,\n",
    "                 energy_log_path)\n",
    "        print(\"data[{}]: simulated\".format(num))\n",
    "        sys.stdout.flush()\n",
    "    #for num in range(head_index, end_index):\n",
    "    # evalu = functools.partial(simulate, \n",
    "    #                           data = data, \n",
    "    #                           input_data = input_data, \n",
    "    #                           str_a = str_a, \n",
    "    #                           str_b = str_b,\n",
    "    #                           str_a_star = str_a_star,  \n",
    "    #                           str_b_star = str_b_star,\n",
    "    #                           length_dict = length_dict, \n",
    "    #                           output_folder = output_folder, \n",
    "    #                           output_ATGC_folder = output_ATGC_folder)\n",
    "    # print(\"eval set OK\\n\")\n",
    "    # with Pool(cfg.poolnum) as p:\n",
    "    #     res = p.map(evalu, range(head_index, end_index+1))\n",
    "    # sys.stdout.flush()\n",
    "    # print(\"map end 🗺\\n\")\n",
    "    \n",
    "    \n",
    "#     record_cube = pd.Series([a for a,_ in res])\n",
    "#     record_convexhull = pd.Series([a for _,a in res])\n",
    "\n",
    "#     cube_data = pd.DataFrame({\"size\":record_cube})\n",
    "#     convexhull_data = pd.DataFrame({\"size\":record_convexhull})\n",
    "\n",
    "#     cube_data.plot()\n",
    "#     plt.savefig('test_cube.png')\n",
    "#     convexhull_data.plot()\n",
    "#     plt.savefig('test_convexhull.png')\n",
    "    return data[head_index], data[end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oxdna_energy_mean(energy_log_path):\n",
    "    energy_log = pd.read_csv(energy_log_path)\n",
    "    energy_mean = energy_log.loc[:,\"potential_energy\"].mean()\n",
    "    \n",
    "    with open(os.path.dirname(energy_log_path)+\"/oxdna_energy_mean.csv\",\"w\") as f:\n",
    "        f.writelines([\"oxdna_energy_mean\",\"\\n\",str(energy_mean)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    \n",
    "    #sys.argv[1]はoutput***.pil, sys.argv[2]は出力先ディレクトリパス\n",
    "    with open(args[1],'r') as file:#sys.argv[1]はoutput***.pil\n",
    "\n",
    "        data = file.readlines()\n",
    "        #get_output_pilfile.pyから、argsとして出力先フォルダパスを受け取る\n",
    "        output_ATGC_folder = args[2]#sys.argv[2]は出力先ディレクトリパス\n",
    "        output_folder = args[2]\n",
    "        \n",
    "        energy_log_path = output_folder + \"/energy_log.csv\"\n",
    "        if not os.path.exists(output_ATGC_folder):\n",
    "            os.makedirs(output_ATGC_folder)\n",
    "\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "            \n",
    "        with open(energy_log_path,\"w\") as energy_log:\n",
    "            energy_log.writelines([\"id\",\",\",\n",
    "                                   \"expected_number_of_strands\", \",\",\n",
    "                                   \"actual_number_of_strands\", \",\", \n",
    "                                   \"potential_energy\", \"\\n\"])\n",
    "        start, end = make_output(\n",
    "            data, output_folder, output_ATGC_folder,energy_log_path)\n",
    "        #今後make_outputに渡す出力先フォルダ名は一つに統合したい。\n",
    "        oxdna_energy_mean(energy_log_path)\n",
    "        \n",
    "        print (\"simuration complete : \\n\")\n",
    "        print(\"start : \", start)\n",
    "        print(\"end : \", end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "# import glob\n",
    "# import os\n",
    "# for pils in glob.glob(\"2023-07-31/sim_result_peppercorn*/*_result.pil\"):\n",
    "#     main([\"\",pils,os.path.dirname(pils)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    args = sys.argv\n",
    "    sys.exit(main(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9.0",
   "language": "python",
   "name": "python3.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc-autonumbering": false,
  "vscode": {
   "interpreter": {
    "hash": "cf26dc9fe348c759e74c27c0008c9a61c31eebfc82e2eaec1db085887aa19aca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

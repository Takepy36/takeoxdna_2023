{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df027081-579d-4b23-9214-8b4cdee7617f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import GPy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import importlib\n",
    "import config as cfg\n",
    "importlib.reload(cfg)\n",
    "import seaborn as sns\n",
    "# Make NumPy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "#まずpil_maker.pyを実行してpilファイルを生成してください\n",
    "#pilファイルができたら、get_output_pilfile.pyでoxDNAを実行してください\n",
    "#get_strand_data.pyでstrand一覧CSVを生成してください\n",
    "#最後にこのプログラムを使ってください\n",
    "import time\n",
    "import csv\n",
    "from scipy.stats import linregress\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import model_selection, svm, datasets\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1411f599-09a4-4004-9a73-c9b0ea625bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datetime_folder():\n",
    "    dt = str(datetime.datetime.now().strftime('%Y%m%d_%H%M'))\n",
    "    dirpath = os.path.join(cfg.result_parent_dir,dt)\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.mkdir(dirpath)\n",
    "    return dirpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba421a20-3f3a-4adc-8be6-3a5da05aca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_readme(dirpath):\n",
    "    with open(os.path.join(dirpath,\"readme.txt\"), \"w\") as f:\n",
    "        f.write(\"各種ファイルの解説\\n\")\n",
    "        f.write(\n",
    "            \"df_test.p : \\n\"\\\n",
    "            \"0~255列目までは、\"\\\n",
    "            \"256通りある材料strandの組み合わせの有無が0,1の値で入っています。\"\\\n",
    "            \"256列目のenergyは、出来上がる構造の位置エネルギー値です。\"\\\n",
    "            \"257列目のstrandsは、実際に使用される材料strandのリストです。\"\\\n",
    "            \"\\n\\n\")\n",
    "        f.write(\n",
    "            \"x_train.p, y_train.p, x_test.p, y_test.p : \\n\"\\\n",
    "            \"xは256通りある材料strandの組み合わせの有無を表す0,1の値です(0~255)。\"\\\n",
    "            \"yはxのstrand組から作られる構造の位置エネルギー値です。\"\\\n",
    "            \"それぞれ、訓練用と、テスト用のデータに分けられています。\"\\\n",
    "            \"\\n\\n\")\n",
    "        f.write(\n",
    "            \"x_train0.p, y_train0.p, x_test0.p, y_test0.p : \\n\"\\\n",
    "            \"strandsの実際の組が最後尾に含まれます。それ以外は訓練・テストデータ\"\\\n",
    "            \"と内容は同じです。\"\\\n",
    "            \"\\n\\n\"\n",
    "        )\n",
    "        f.write(\n",
    "            \"param_optimized_svm.txt : \\n\"\\\n",
    "            \"サポートベクターマシンの回帰分析モデルのハイパーパラメータです。\"\\\n",
    "            \"\\n\\n\"\n",
    "        )\n",
    "        f.write(\n",
    "            \"optimized_svm.p : \\n\"\\\n",
    "            \"サポートベクターマシンの回帰分析モデルです。\"\\\n",
    "            \"strandsの組み合わせxから、位置エネルギー値yを予測します。\"\\\n",
    "            \"\\n\\n\"\n",
    "        )\n",
    "        f.write(\n",
    "            \"optimized_svm_train_result.p : \\n\"\\\n",
    "            \"モデルがx_train,y_trainを教師として学習した結果です。\"\\\n",
    "            \"０列目のmodel_predict_x_trainは、x_trainをもとにyを予測した結果です。\"\\\n",
    "            \"y_trainは、x_trainに対応する実際のyです。\"\\\n",
    "            \"defferenceは、model_predict_x_trainとy_trainの差です。\"\\\n",
    "            \"\\n\\n\"\n",
    "        )\n",
    "        f.write(\n",
    "            \"optimized_svm_test_result.p : \\n\"\\\n",
    "            \"モデルがx_testに対する位置エネルギー値yを予測した結果です。\"\\\n",
    "            \"０列目のmodel_predict_x_testは、x_testをもとにyを予測した結果です。\"\\\n",
    "            \"y_testは、x_testに対応する実際のyです。\"\\\n",
    "            \"defferenceは、model_predict_x_testとy_testの差です。\"\\\n",
    "            \"\\n\\n\"\n",
    "        )\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8488cf54-54d8-4653-b8fc-3f4f6f39e1e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_datetime_folder():\n",
    "    dt = str(datetime.datetime.now().strftime('%Y%m%d_%H%M'))\n",
    "    dirpath = os.path.join(cfg.result_parent_dir,dt)\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.mkdir(dirpath)\n",
    "    return dirpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cbae51e-0838-4451-8527-5738d3feca91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dump_to_pickle(dirpath,variable_list,namelist):\n",
    "    for i,filename in enumerate(namelist):\n",
    "        path = os.path.join(dirpath, filename + \".p\")\n",
    "        f = open(path, 'wb')\n",
    "        pickle.dump(variable_list[i], f)\n",
    "        print(\"saved : \",path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fdc6651-69b3-414f-9e0e-8bec5c435c17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_df_for_learning(dirpath):\n",
    "    df = pd.read_csv(os.path.join(cfg.result_parent_dir,\"strands.csv\"))\n",
    "    df_groupby = df.groupby(\"pilfile_path\")\n",
    "    #df[\"pilfile_path\"].values\n",
    "    df_groupby.get_group(df[\"pilfile_path\"].values[0])#.loc[:,\"strand_num\"])\n",
    "    #strand_set_numは理論上、0 ~ 255まで存在する。\n",
    "    path_and_code = []\n",
    "    for i, data in enumerate(df_groupby):\n",
    "        test_df = data[1]\n",
    "        arr = [\"0\"] * 256\n",
    "        strand_list = []\n",
    "        for i,num in enumerate(test_df.loc[:,\"strand_set_num\"].values):\n",
    "            arr[255-num] = \"1\"\n",
    "            #strand_list.append[test_df.loc[:,\"strand_set\"]]\n",
    "        #print(test_df.loc[:,\"strand_set\"])\n",
    "\n",
    "\n",
    "\n",
    "        energy_path = os.path.dirname(data[0]) + \"/mean.csv\"\n",
    "\n",
    "        try:\n",
    "            energy = pd.read_csv(energy_path).iloc[3,1]\n",
    "            #path_and_code.append([data[0],int(\"\".join(arr),2),energy])\n",
    "            path_and_code.append(\n",
    "                [data[0],\n",
    "                 list(test_df.loc[:,\"strand_set\"]),\n",
    "                 arr,\n",
    "                 int(\"\".join(arr),2),energy]\n",
    "            )\n",
    "        except:\n",
    "            #path_and_code.append([data[0],int(\"\".join(arr),2),None])\n",
    "            path_and_code.append(\n",
    "                [data[0],\n",
    "                 list(test_df.loc[:,\"strand_set\"]),\n",
    "                 arr,\n",
    "                 int(\"\".join(arr),2),\n",
    "                 None]\n",
    "            )\n",
    "    path_and_code_data = pd.DataFrame(path_and_code)\n",
    "    path_and_code_data.columns = [\"path\",\"strands\",\"code_num\",\"code_num2\",\"energy\"]\n",
    "    path_and_code_data.to_csv(os.path.join(cfg.result_parent_dir,\"path_and_code_data.csv\"),index=False)\n",
    "    df01 = pd.DataFrame([])\n",
    "    for lst in path_and_code_data.loc[:,\"code_num\"].values:\n",
    "        #display(pd.DataFrame(lst).T)\n",
    "        df01 = pd.concat([df01,pd.DataFrame(lst).T]).reset_index(drop=True).astype(int)\n",
    "        df_test = pd.concat([df01,pd.DataFrame(path_and_code_data.loc[:,\"energy\"])],axis=1)\n",
    "        df_test = pd.concat([df_test,path_and_code_data.loc[:,\"strands\"]],axis=1)\n",
    "        df_test = df_test.dropna()\n",
    "        \n",
    "    dump_to_pickle(dirpath,[df_test],[\"df_test\"])\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6128acf6-dc2e-4e5b-aa34-ad3bc7b50ebb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_datasets(dirpath,df_test):\n",
    "    \n",
    "    dataset0 = df_test.copy()\n",
    "    x_train0, x_test0, y_train0, y_test0 = train_test_split(\n",
    "        dataset0.drop(\"energy\",axis = 1),\n",
    "        dataset0.loc[:,\"energy\"],\n",
    "        test_size=0.2\n",
    "    )\n",
    "    \n",
    "    #strandsを含むデータセットをファイルに保存しておく。\n",
    "    \n",
    "    x_train = x_train0.drop(\"strands\",axis=1)\n",
    "    x_test = x_test0.drop(\"strands\",axis=1)\n",
    "    y_train = y_train0\n",
    "    y_test = y_test0\n",
    "    \n",
    "    ytrain_mean = y_train.mean()\n",
    "    ytrain_std = y_train.std()\n",
    "\n",
    "    ytest_mean = y_test.mean()\n",
    "    ytest_std = y_test.std()\n",
    "    \n",
    "    variable_list = [x_train,y_train,x_test,y_test,x_train0,y_train0,x_test0,y_test0]\n",
    "    namelist = [\"x_train\",\"y_train\",\"x_test\",\"y_test\",\"x_train0\",\"y_train0\",\"x_test0\",\"y_test0\"]\n",
    "    dump_to_pickle(dirpath,variable_list,namelist)\n",
    "\n",
    "    return x_train,y_train,x_test,y_test,x_train0,y_train0,x_test0,y_test0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a40c9540-519e-4b7a-ace0-5c5a0078670a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    print(hist.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60102e09-0276-4c87-a3df-4286d795e404",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_svm(dirpath,param_filename,gamma,C,epsilon,\n",
    "             kernel=\"rbf\",degree=3,coef0=0.0,tol=0.001,\n",
    "             shrinking=True,cache_size=200,\n",
    "             verbose=False,max_iter= -1):\n",
    "    \n",
    "    with open(os.path.join(dirpath,param_filename), \"w\") as f:\n",
    "        f.write(\"kernel:\"+\"\\t\"+str(kernel)+\"\\n\")\n",
    "        f.write(\"degree:\"+\"\\t\"+str(degree)+\"\\n\")\n",
    "        f.write(\"gamma:\"+\"\\t\"+str(gamma)+\"\\n\")\n",
    "        f.write(\"coef0:\"+\"\\t\"+str(coef0)+\"\\n\")\n",
    "        f.write(\"tol:\"+\"\\t\"+str(tol)+\"\\n\")\n",
    "        f.write(\"C:\"+\"\\t\"+str(C)+\"\\n\")\n",
    "        f.write(\"epsilon:\"+\"\\t\"+str(epsilon)+\"\\n\")\n",
    "        f.write(\"shrinking:\"+\"\\t\"+str(shrinking)+\"\\n\")\n",
    "        f.write(\"cache_size:\"+\"\\t\"+str(cache_size)+\"\\n\")\n",
    "        f.write(\"verbose:\"+\"\\t\"+str(verbose)+\"\\n\")\n",
    "        f.write(\"max_iter:\"+\"\\t\"+str(max_iter)+\"\\n\")\n",
    "    f.close()\n",
    "    svr = SVR(gamma=gamma,C=C,epsilon=epsilon,\n",
    "             kernel=kernel,degree=degree,coef0=coef0,tol=tol,\n",
    "             shrinking=shrinking,cache_size=cache_size,\n",
    "             verbose=verbose,max_iter= max_iter)\n",
    "    return svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2cb8019-95fe-4d2d-93c0-451e93d5f006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_svm_result(dirpath,train_filename,test_filename,model,x_train,y_train,x_test,y_test):\n",
    "    #ndarrayに変換\n",
    "    xtn = x_train.values\n",
    "    ytn = y_train.values\n",
    "    xtt = x_test.values\n",
    "    ytt = y_test.values\n",
    "    #学習結果\n",
    "    svm_train_result = pd.concat(\n",
    "    [pd.DataFrame(model.predict(xtn)),\n",
    "     y_train.reset_index(drop=True),\n",
    "     pd.DataFrame(model.predict(xtn)-ytn)],\n",
    "    axis = 1)\n",
    "    svm_train_result.index = y_train.index\n",
    "    svm_train_result.columns = [\"model_predict_x_train\",\"y_train\",\"defference\"]\n",
    "    \n",
    "    #テスト結果\n",
    "    svm_test_result = pd.concat(\n",
    "    [pd.DataFrame(model.predict(xtt)),\n",
    "     y_test.reset_index(drop=True),\n",
    "     pd.DataFrame(model.predict(xtt)-ytt)],\n",
    "    axis = 1)\n",
    "    svm_test_result.index = y_test.index\n",
    "    svm_test_result.columns = [\"model_predict_x_test\",\"y_test\",\"defference\"]\n",
    "    \n",
    "    dump_to_pickle(dirpath,[svm_train_result,svm_test_result],[train_filename,test_filename])\n",
    "\n",
    "    return svm_train_result,svm_test_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92067ce7-c054-4458-9561-c8f2ea0da437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_optimized_svm(dirpath,Xtrain,ytrain,Xtest,ytest,bagging=False):\n",
    "    #試したいパラメータの候補。\n",
    "    svrcs = 2**np.arange( -5, 11, dtype=float)          # Candidates of C\n",
    "    svrepsilons = 2**np.arange( -10, 1, dtype=float)    # Candidates of epsilon\n",
    "    svrgammas = 2**np.arange( -20, 11, dtype=float)     # Candidates of gamma\n",
    "    foldnumber = 5 # \"foldnumber\"-fold cross-validation\n",
    "    nmberoftrainingsamples = len(Xtrain)\n",
    "    nmberoftestsamples = len(Xtest)\n",
    "    \n",
    "    # autoscaledXtrain = (Xtrain - Xtrain.mean(axis=0)) / Xtrain.std(axis=0, ddof=1)\n",
    "    # autoscaledytrain = (ytrain - ytrain.mean()) / ytrain.std(ddof=1)\n",
    "    # autoscaledXtest =  (Xtest - Xtrain.mean(axis=0)) / Xtrain.std(axis=0, ddof=1)\n",
    "    #標準化するとNaNがたくさんできるので、今回は使っていない\n",
    "    \n",
    "    autoscaledXtrain = Xtrain\n",
    "    autoscaledytrain = ytrain\n",
    "    autoscaledXtest = Xtest\n",
    "    \n",
    "    #Optimize gamma by maximizing variance in Gram matrix\n",
    "    numpyautoscaledXtrain = np.array(autoscaledXtrain)\n",
    "    varianceofgrammatrix = list()\n",
    "    for svrgamma in svrgammas:\n",
    "        #grammatrix = np.exp(-svrgamma*((numpyautoscaledXtrain[:, np.newaxis] - numpyautoscaledXtrain)**2).sum(axis=2))\n",
    "        a =  -svrgamma*((numpyautoscaledXtrain[:, np.newaxis] - numpyautoscaledXtrain)**2)\n",
    "        grammatrix = np.exp(np.nansum(a,axis=2))\n",
    "        varianceofgrammatrix.append(grammatrix.var(ddof=1))\n",
    "        \n",
    "    optimalsvrgamma = svrgammas[ np.where( varianceofgrammatrix == np.max(varianceofgrammatrix) )[0][0] ]\n",
    "        \n",
    "    # Optimize epsilon with cross-validation\n",
    "    svrmodelincv = GridSearchCV(svm.SVR(kernel='rbf', C=3, gamma=optimalsvrgamma), {'epsilon':svrepsilons}, cv=foldnumber )\n",
    "    svrmodelincv.fit(autoscaledXtrain, autoscaledytrain)\n",
    "    optimalsvrepsilon = svrmodelincv.best_params_['epsilon']\n",
    "    \n",
    "    # Optimize C with cross-validation\n",
    "    svrmodelincv = GridSearchCV(svm.SVR(kernel='rbf', epsilon=optimalsvrepsilon, gamma=optimalsvrgamma), {'C':svrcs}, cv=foldnumber )\n",
    "    svrmodelincv.fit(autoscaledXtrain, autoscaledytrain)\n",
    "    optimalsvrc = svrmodelincv.best_params_['C']\n",
    "\n",
    "    # Optimize gamma with cross-validation (optional)\n",
    "    svrmodelincv = GridSearchCV(svm.SVR(kernel='rbf', epsilon=optimalsvrepsilon, C=optimalsvrc), {'gamma':svrgammas}, cv=foldnumber )\n",
    "    svrmodelincv.fit(autoscaledXtrain, autoscaledytrain)\n",
    "    optimalsvrgamma = svrmodelincv.best_params_['gamma']\n",
    "    \n",
    "    print (\"C: {0}, Epsion: {1}, Gamma: {2}\".format(optimalsvrc, optimalsvrepsilon, optimalsvrgamma))\n",
    "    \n",
    "    #regressionmodel = svm.SVR(kernel='rbf', C=optimalsvrc, epsilon=optimalsvrepsilon, gamma=optimalsvrgamma)\n",
    "    regressionmodel = make_svm(dirpath,\"param_optimized_svm.txt\",optimalsvrgamma,optimalsvrc,optimalsvrepsilon)\n",
    "    dump_to_pickle(dirpath,[regressionmodel],[\"empty_svm\"])\n",
    "    regressionmodel.fit(autoscaledXtrain, autoscaledytrain)\n",
    "    dump_to_pickle(dirpath,[regressionmodel],[\"optimized_svm\"])\n",
    "    \n",
    "    #ついでなので、baggingを適用したものも追加。\n",
    "    if bagging == True:\n",
    "        regr2 = BaggingRegressor(estimator=regressionmodel,\n",
    "                             n_estimators=10,\n",
    "                             random_state=0)\n",
    "        regr2.fit(autoscaledXtrain, autoscaledytrain)\n",
    "        dump_to_pickle(dirpath,[regr2],[\"bagging_optimized_svm\"])\n",
    "        return regressionmodel,regr2\n",
    "    \n",
    "    return regressionmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4743409a-cb6a-42b5-9375-affa527914cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    dirpath = make_datetime_folder()\n",
    "    df_test = make_df_for_learning(dirpath)\n",
    "    x_train,y_train,x_test,y_test,x_train0,y_train0,x_test0,y_test0 = make_datasets(dirpath,df_test)\n",
    "    regressionmodel = make_optimized_svm(dirpath,x_train,y_train,x_test,y_test)\n",
    "    op_svm_train_result,op_svm_test_result = make_svm_result(dirpath,\"optimized_svm_train_result\",\"optimized_svm_test_result\",regressionmodel,x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94877595-e616-4bc3-8095-c959c8ac9be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved :  2022-12-19/20230325_1538/df_test.p\n",
      "saved :  2022-12-19/20230325_1538/x_train.p\n",
      "saved :  2022-12-19/20230325_1538/y_train.p\n",
      "saved :  2022-12-19/20230325_1538/x_test.p\n",
      "saved :  2022-12-19/20230325_1538/y_test.p\n",
      "saved :  2022-12-19/20230325_1538/x_train0.p\n",
      "saved :  2022-12-19/20230325_1538/y_train0.p\n",
      "saved :  2022-12-19/20230325_1538/x_test0.p\n",
      "saved :  2022-12-19/20230325_1538/y_test0.p\n",
      "C: 0.25, Epsion: 0.0078125, Gamma: 0.5\n",
      "saved :  2022-12-19/20230325_1538/empty_svm.p\n",
      "saved :  2022-12-19/20230325_1538/optimized_svm.p\n",
      "saved :  2022-12-19/20230325_1538/optimized_svm_train_result.p\n",
      "saved :  2022-12-19/20230325_1538/optimized_svm_test_result.p\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38bcbe1-12e3-4e07-aecc-5fd873bcc006",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
